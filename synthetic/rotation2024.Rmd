---
title: "R Notebook"
output: html_notebook
---



```{r}
rm(list = ls())
library(MASS)
library(splines)
library(latex2exp)
source('..//toSource.R')



expit <- function(x){ exp(x)/(1+exp(x)) };

logit <- function(x){ log(x/(1-x)) }

# n <- 4*2000; 
n_vec <- seq(from=2000,to=8000,by=500)
nsim <- length(n_vec);

set.seed(1)
cate_hat_mat <- data.frame(matrix(nrow=nsim,ncol=7))
res <- data.frame(matrix(nrow=nsim,ncol=7))
colnames(cate_hat_mat) =colnames(res)= c("plugin","forster_poly","forster_ns","forster_bs", "forster_poly_cross","forster_ns_cross","forster_bs_cross")
res$N = n_vec
cate_hat_mat$N = n_vec
for (i in 1:nsim){
  n = n_vec[i]
  s <- sort(rep(1:2,n/2));
  
  
  # Measured covariate
  x <- runif(n,-1,1)
  # unmeasured confounder
  u <- rbinom(n,1,prob=0.5)
  # IV:
  # Restriction: Independence from U
  z <- rbinom(n,1,prob = 0.8)
  # treatment variable: 
  # Restrictions: IV relevance
  delta_d <- tanh(-x)
  delta <- tanh(0.5*x)
  op_d <- exp(x)
  p_0d <- 1/2/(op_d-1)*(op_d*(2 - delta_d) + delta_d - sqrt((op_d*(delta_d-2) - delta_d)^2 + 4*op_d*(1-delta_d)*(1-op_d)))
  p_1d <- p_0d + delta_d
  ps <- p_0d + z*delta_d + 0.1*(2*u-1)
  range(ps)
  a <- rbinom(n,1,ps);

  
  #Restrictions: Exclusion restriction and no A,U interaction.
  error <- rnorm(n,sd=0.02)
  p_2 <- function(x,a,u){
    f_x = (x <= -.5)*0.5*(x+2)^2 + (x > -.5 & x<0)*(x/2+0.875) +
    (x>0 & x<.5)*(-5*(x-0.2)^2 +1.075) + (x>.5)*(x+0.125) 
    return(f_x + z*delta_d*delta + 0.1*(2*u-1)) 
  }
  
  mu0 <- p_2(x,rep(0,n),u);
  mu1 <- p_2(x,rep(1,n),u);
  cate <- mu1-mu0
  tau <- mean(cate)
  # outcome
  # under assumption 4.a) no A by U interaction
  y <- p_2(x,a,u) + error

  
  df <- data.frame(X=x,Y=y,Z=z,A=a, S= s)

  # function for cross fitting 1 and 2
  
  
 
  I_1 <- df[df$S==1,]
  I_2 <- df[df$S==2,]
 
  
  po_fitter <- function(sub_df){
    ## estimate nuisance functions
    # want to emphasize ability to use non-parametric nuissance functions  

  
    model_A1 = glm(A ~ ns(X),data = sub_df[sub_df$Z==1,],family = binomial())
    model_A0 = glm(A ~ ns(X),data = sub_df[sub_df$Z==0,],family = binomial())
    
    EA1hat <- predict(model_A1,newdata = sub_df,type = "response")
    EA0hat <- predict(model_A0,newdata = sub_df,type = "response")
    EY1hat <- predict(smooth.spline(sub_df$X[sub_df$Z==1] , sub_df$Y[sub_df$Z==1]),sub_df$X)$y
    EY0hat <- predict(smooth.spline(sub_df$X[sub_df$Z==0] , sub_df$Y[sub_df$Z==0]),sub_df$X)$y
    
    betahat <- (EY1hat-EY0hat)/(EA1hat - EA0hat)
    deltahat <- (EA1hat - EA0hat)
    #hard coded. Change later
    f_z <- 0.8*sub_df$Z + 0.2*(1-sub_df$Z)
    pseudoIV <- (2*sub_df$Z - 1)/f_z * (sub_df$Y - sub_df$A*betahat - EY0hat + EA0hat*betahat)/deltahat + betahat
    return(pseudoIV)
  }
  I_1$PsuedoO= po_fitter(I_1)
  I_2$PsuedoO = po_fitter(I_2)
  
    
    
    
  
  

 

  ## construct estimators

  # do we need both IV and Covariate? No, just the covariate.
  forster_poly_1 = series_df(I_1$X,I_1$PsuedoO,I_2$X,df=4, type = "forster", basis_type = "poly")[[1]]
  forster_ns_1 = series_df(I_1$X,I_1$PsuedoO,I_2$X,df=4, type = "forster", basis_type = "ns")[[1]]
  forster_bs_1 = series_df(I_1$X,I_1$PsuedoO,I_2$X,df=4, type = "forster", basis_type = "bs")[[1]]
  
  forster_poly_2 = series_df(I_2$X,I_2$PsuedoO,I_1$X,df=4, type = "forster", basis_type = "poly")[[1]]
  forster_ns_2 = series_df(I_2$X,I_2$PsuedoO,I_1$X,df=4, type = "forster", basis_type = "ns")[[1]]
  forster_bs_2 = series_df(I_2$X,I_2$PsuedoO,I_1$X,df=4, type = "forster", basis_type = "bs")[[1]]
  
  forster_poly_cross = mean(forster_poly_1 + forster_poly_2)
  forster_ns_cross = mean(forster_ns_1 + forster_ns_2)
  forster_bs_cross = mean(forster_bs_1 + forster_bs_2)
  
  # ls_poly = series_df(I_1$X,I_1$PsudoO,I_2$X,df=4, type = "ls", basis_type = "poly")[[1]]
  # ls_ns = series_df(I_1$X,I_1$PsudoO,I_2$X,df=4, type = "ls", basis_type = "ns")[[1]]
  # ls_bs = series_df(I_1$X,I_1$PsudoO,I_2$X,df=4, type = "ls", basis_type = "bs")[[1]]
  
  
  m_A1 = glm(A ~ ns(X),data = df[df$Z==1,],family = binomial())
  summary(m_A1)
  m_A0 = glm(A ~ ns(X),data = df[df$Z==0,],family = binomial())
  p_EA1hat <- predict(m_A1,newdata = df,type = "response")
  p_EA0hat <- predict(m_A0,newdata = df,type = "response")
  p_EY1hat <- predict(smooth.spline(df$X[df$Z==1] , df$Y[df$Z==1]),df$X)$y
  p_EY0hat <- predict(smooth.spline(df$X[df$Z==0] , df$Y[df$Z==0]),df$X)$y
    
  plugin <- (p_EY1hat-p_EY0hat)/(p_EA1hat - p_EA0hat)
  
  

  ## save MSEs
  res$plugin[i] <- mean((plugin-tau)^2)
  res$forster_poly[i] <- mean((forster_poly_1-tau)^2)
  res$forster_ns[i] <- mean((forster_ns_1-tau)^2)
  res$forster_bs[i] <- mean((forster_bs_1-tau)^2)
  
  res$forster_poly_cross[i] <- mean((forster_poly_cross-tau)^2)
  res$forster_ns_cross[i] <- mean((forster_ns_cross-tau)^2)
  res$forster_bs_cross[i] <- mean((forster_bs_cross-tau)^2)
  
  
  # res$ls_poly[i] <-mean((ls_poly-tau)^2)
  # res$ls_ns[i] <- mean((ls_ns-tau)^2)
  # res$ls_bs[i] <- mean((ls_bs -tau)^2)
  # 
  cate_hat_mat$plugin[i] <- mean(plugin)
  cate_hat_mat$forster_poly[i] <- mean(forster_poly_1)
  cate_hat_mat$forster_ns[i] <- mean(forster_ns_1)
  cate_hat_mat$forster_bs[i] <- mean(forster_bs_1)
  cate_hat_mat$forster_poly_cross[i] <- mean(forster_poly_cross)
  cate_hat_mat$forster_ns_cross[i] <- mean(forster_ns_cross)
  cate_hat_mat$forster_bs_cross[i] <- mean(forster_bs_cross)
  
  # cate_hat_mat$ls_poly[i] <-mean(ls_poly-tau)
  # cate_hat_mat$ls_ns[i] <- mean(ls_ns-tau)
  # cate_hat_mat$ls_bs[i] <- mean(ls_bs -tau)
  
}

```

```{r}
#plotting


ggplot(res, aes(x = N))+
  
  geom_line(aes(y = forster_bs, colour = "forster_bs"))+
  geom_line(aes(y = forster_bs_cross, colour = "forster_bs_cross"))+
  
  geom_line(aes(y = forster_ns, colour = "forster_ns"))+
  geom_line(aes(y = forster_ns_cross, colour = "forster_ns_cross"))+
  
  geom_line(aes(y = forster_poly, colour = "forster_poly"))+
  geom_line(aes(y = forster_poly_cross, colour = "forster_poly_cross"))+
  
  geom_line(aes(y = plugin, colour = "plugin"))+
  scale_color_manual(values=c('blue','cyan','darkgreen','green','purple' ,'orchid' ,'red'))+
  ggtitle("MSE(N) comparison")+
  xlab("Number of observations:2000-8000")+
  ylab("MSE:1/n[(Y - Y*)^2]")
  


```



```{r}


rateseq <- seq(0.1,0.5,by=0.05);
1/(n/4)^rateseq
1/(n/4)^rateseq
```

